{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d435bae-c85f-4368-8cd5-0eff0928458e",
      "metadata": {
        "id": "9d435bae-c85f-4368-8cd5-0eff0928458e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CR_HBbn6JD7",
        "outputId": "149b9d27-4d37-4761-d585-ce1615325be2"
      },
      "id": "0CR_HBbn6JD7",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트하기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 특정 디렉토리로 이동하기\n",
        "import os\n",
        "\n",
        "# 예: My Drive 내의 'project' 폴더로 이동\n",
        "\n",
        "project_path = '/content/drive/MyDrive/GPU-MODE/lectures'\n",
        "# 디렉토리 존재 여부 확인 후 이동\n",
        "if os.path.exists(project_path):\n",
        "    os.chdir(project_path)\n",
        "    print(f\"현재 작업 디렉토리: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"디렉토리가 존재하지 않습니다: {project_path}\")\n",
        "\n",
        "# 현재 디렉토리 내용 확인\n",
        "print(\"\\n현재 디렉토리 내용:\")\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm3bcqaknXUi",
        "outputId": "f1f33164-e388-42f5-9fea-341fae2ceb47"
      },
      "id": "Xm3bcqaknXUi",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "현재 작업 디렉토리: /content/drive/MyDrive/GPU-MODE/lectures\n",
            "\n",
            "현재 디렉토리 내용:\n",
            "['LICENSE', 'README.md', '.gitignore', '.DS_Store', 'lecture_017', 'lecture_029', 'lecture_035', 'lecture_042', 'lecture_011', 'lecture_018', 'lecture_003', 'lecture_002', 'lecture_004', 'lecture_005', 'lecture_033', 'lecture_031', 'lecture_013', 'lecture_038', 'lecture_014', 'lecture_009', '.git', 'lecture_025', 'lecture_036', 'lecture_001', 'lecture_037', 'lecture_030', 'lecture_008', 'my_utils.py', '__pycache__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
      "metadata": {
        "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e"
      },
      "outputs": [],
      "source": [
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bbda41fd-dbbf-47d4-807a-67ad565b3bc8",
      "metadata": {
        "id": "bbda41fd-dbbf-47d4-807a-67ad565b3bc8"
      },
      "outputs": [],
      "source": [
        "dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5b57350f-3ff6-4e10-8635-040c3736220d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b57350f-3ff6-4e10-8635-040c3736220d",
        "outputId": "f43f761a-a09c-4497-cdb4-dc284c2d8ac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dim3(x=2, y=3, z=1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "d = dim3(2,3)\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ca90d679-3fba-4903-8e14-7ef9efb3bf89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca90d679-3fba-4903-8e14-7ef9efb3bf89",
        "outputId": "aedd0921-4c81-454b-9853-a50f0a383ad3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "d.x,d.y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "14e41709-f1f3-40c1-aa20-bd19737f3d86",
      "metadata": {
        "id": "14e41709-f1f3-40c1-aa20-bd19737f3d86"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2, linewidth=140)\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db47935d-8477-4116-9538-369c759322bd",
      "metadata": {
        "id": "db47935d-8477-4116-9538-369c759322bd"
      },
      "outputs": [],
      "source": [
        "sys.path.insert(0, '..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a76aa950-6f87-452d-b048-82da11be0b24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a76aa950-6f87-452d-b048-82da11be0b24",
        "outputId": "d2a89161-fff4-4fb8-f0f7-ecbd20c84490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LICENSE', 'README.md', '.gitignore', '.DS_Store', 'lecture_017', 'lecture_029', 'lecture_035', 'lecture_042', 'lecture_011', 'lecture_018', 'lecture_003', 'lecture_002', 'lecture_004', 'lecture_005', 'lecture_033', 'lecture_031', 'lecture_013', 'lecture_038', 'lecture_014', 'lecture_009', '.git', 'lecture_025', 'lecture_036', 'lecture_001', 'lecture_037', 'lecture_030', 'lecture_008', 'my_utils.py', '__pycache__']\n"
          ]
        }
      ],
      "source": [
        "# Then install the specific package you need, for example:\n",
        "print(os.listdir())\n",
        "from my_utils import load_cuda,cuda_begin,cdiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "994f69fd-3989-46e2-ad84-71b7450f1b3f",
      "metadata": {
        "id": "994f69fd-3989-46e2-ad84-71b7450f1b3f"
      },
      "outputs": [],
      "source": [
        "%load_ext wurlitzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ed0d99b2-bf34-4e9c-99e5-0ebf4e4b02d7",
      "metadata": {
        "id": "ed0d99b2-bf34-4e9c-99e5-0ebf4e4b02d7"
      },
      "outputs": [],
      "source": [
        "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
        "torch.manual_seed(42);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cc38ccaa-c802-46c2-962a-e1f83eba49d0",
      "metadata": {
        "id": "cc38ccaa-c802-46c2-962a-e1f83eba49d0"
      },
      "outputs": [],
      "source": [
        "\n",
        "m1 = torch.rand(5120, 256)\n",
        "m1s = m1[:4]\n",
        "m2 = torch.rand(256,5120)\n",
        "m2s = m2[:,:4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28662938-ef33-410b-96d4-d7d503c696d6",
      "metadata": {
        "id": "28662938-ef33-410b-96d4-d7d503c696d6"
      },
      "source": [
        "## Reminder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c9421c9-6cd5-479e-b3f2-7a3a8d2a7b43",
      "metadata": {
        "id": "0c9421c9-6cd5-479e-b3f2-7a3a8d2a7b43"
      },
      "source": [
        "### 2d Python kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2ef592ed-b605-46f5-b72d-662ab46a55e8",
      "metadata": {
        "id": "2ef592ed-b605-46f5-b72d-662ab46a55e8"
      },
      "outputs": [],
      "source": [
        "# CUDA GPU Kernel을 CPU에서 반복하여 수행.\n",
        "# f : 실행 함수.\n",
        "def blk_kernel2d(f, blocks, threads, *args):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            for j0 in range(threads.y):\n",
        "                for j1 in range(threads.x): f(dim3(i1,i0), dim3(j1,j0), threads, *args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "62f8923f-8072-4f52-a644-6576f7dfe352",
      "metadata": {
        "id": "62f8923f-8072-4f52-a644-6576f7dfe352"
      },
      "outputs": [],
      "source": [
        "# Matrix Mutiplication, out[r][c] = Σ(i=0 to k-1) m[r][i] * n[i][c]\n",
        "def matmul_bk(blockIdx, threadIdx, blockDim, m, n, out, h, w, k):\n",
        "    r = blockIdx.y*blockDim.y + threadIdx.y # row index\n",
        "    c = blockIdx.x*blockDim.x + threadIdx.x # col index\n",
        "\n",
        "    if (r>=h or c>=w): return\n",
        "    o = 0.\n",
        "    for i in range(k): o += m[r*k+i] * n[i*w+c]\n",
        "    out[r*w+c] = o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a53c2202-1169-4ac6-a477-82b82f3c5201",
      "metadata": {
        "id": "a53c2202-1169-4ac6-a477-82b82f3c5201"
      },
      "outputs": [],
      "source": [
        "# 2d Matix Multiplcation\n",
        "# m,n : input array -> [h,k] * [k2,w] = [h,w]\n",
        "def matmul_2d(m, n):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(16,16) # tqb : Threads per block , (16 * 16) = 256 threads\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d(matmul_bk, blocks, tpb,\n",
        "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e54824bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e54824bf",
        "outputId": "0d68fa0b-0c32-4544-8bcd-8284a5ea3035"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# matrix A @ matirx B : A * B 행렬 곱, pytorch 내장 함수\n",
        "torch.isclose(matmul_2d(m1s, m2s), m1s@m2s).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8023ed5e-6adb-4c00-b234-a80bf774baad",
      "metadata": {
        "id": "8023ed5e-6adb-4c00-b234-a80bf774baad"
      },
      "source": [
        "### CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3f85d6e4-bc36-4171-b64e-3447359913e5",
      "metadata": {
        "id": "3f85d6e4-bc36-4171-b64e-3447359913e5"
      },
      "outputs": [],
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n",
        "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (r>=h || c>=w) return;\n",
        "    float o = 0;\n",
        "    for (int i = 0; i<k; ++i) o += m[r*k+i] * n[i*w+c];\n",
        "    out[r*w+c] = o;\n",
        "}\n",
        "\n",
        "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h = m.size(0);\n",
        "    int w = n.size(1);\n",
        "    int k = m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "\n",
        "    dim3 tpb(16,16);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_k<<<blocks, tpb>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SQT90WurNzL0"
      },
      "id": "SQT90WurNzL0"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2a82414f-bd5a-4fb1-9f7f-1f404b8d8a1f",
      "metadata": {
        "id": "2a82414f-bd5a-4fb1-9f7f-1f404b8d8a1f"
      },
      "outputs": [],
      "source": [
        "fname = 'matmul'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d93c0b9a-2f20-460c-8393-3fb241c1ae85",
      "metadata": {
        "id": "d93c0b9a-2f20-460c-8393-3fb241c1ae85"
      },
      "outputs": [],
      "source": [
        "def get_sig(fname, src):\n",
        "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
        "    return res[0]+';' if res else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5b943b71-641c-4ec1-b336-7d04b4930c1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5b943b71-641c-4ec1-b336-7d04b4930c1a",
        "outputId": "7ffb7456-cfdf-486b-e703-24b083f9d84f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "cpp_src = get_sig(fname, cuda_src)\n",
        "cpp_src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9533561e-6426-4c29-92a6-3f968521d795",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "9533561e-6426-4c29-92a6-3f968521d795",
        "outputId": "24460360-4fa3-4d8d-f557-bf588ef910ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "/root/.cache/torch_extensions/py311_cu124/matmul/matmul.so: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-161403717>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/GPU-MODE/lectures/my_utils.py\u001b[0m in \u001b[0;36mload_cuda\u001b[0;34m(cuda_src, cpp_src, funcs, opt, verbose, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-O3 -Xptxas -O3 -Xcompiler -O3\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"-O0 -Xptxas -O0 -Xcompiler -O0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n\u001b[0m\u001b[1;32m     37\u001b[0m                        extra_cuda_cflags=[flags], verbose=verbose, name=name)\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload_inline\u001b[0;34m(name, cpp_sources, cuda_sources, functions, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, with_pytorch_error_handling, keep_intermediates, use_pch)\u001b[0m\n\u001b[1;32m   1721\u001b[0m         \u001b[0msources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_source_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m     return _jit_compile(\n\u001b[0m\u001b[1;32m   1724\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m         \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_exec_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import_module_from_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_python_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2246\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: /root/.cache/torch_extensions/py311_cu124/matmul/matmul.so: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "module = load_cuda(cuda_src, cpp_src, [fname])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4e99ab-d2a7-45ef-a38f-f38ca17e22d0",
      "metadata": {
        "id": "2d4e99ab-d2a7-45ef-a38f-f38ca17e22d0"
      },
      "outputs": [],
      "source": [
        "# contiguous() : 불연속의 배열을 연속으로 치환\n",
        "# cuda : CPU -> GPU load\n",
        "m1c,m2c = m1.contiguous().cuda(),m2.contiguous().cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08507713-c7b5-40b4-a7c0-a9ead64f3017",
      "metadata": {
        "id": "08507713-c7b5-40b4-a7c0-a9ead64f3017"
      },
      "outputs": [],
      "source": [
        "module.matmul(m1c,m2c).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80fc299e-8c08-40f2-9c17-cc1965b0b430",
      "metadata": {
        "id": "80fc299e-8c08-40f2-9c17-cc1965b0b430"
      },
      "outputs": [],
      "source": [
        "torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e2c3eb-813e-4e69-9d90-731a8bf321aa",
      "metadata": {
        "id": "61e2c3eb-813e-4e69-9d90-731a8bf321aa"
      },
      "outputs": [],
      "source": [
        "# Code block을 10번 반복 실행\n",
        "%%timeit -n 10\n",
        "module.matmul(m1c,m2c) # matmul 수행\n",
        "torch.cuda.synchronize() # Sync"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "836bd00e-8c17-4208-a159-aa91a00425ae",
      "metadata": {
        "id": "836bd00e-8c17-4208-a159-aa91a00425ae"
      },
      "source": [
        "When I removed the call to the kernel itself, it took around 50 µs (0.05 ms) to run, so that's the overhead of the call on my machine."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b1cf32-baa7-449b-ac0b-9d787d7bc470",
      "metadata": {
        "id": "32b1cf32-baa7-449b-ac0b-9d787d7bc470"
      },
      "source": [
        "## Shared mem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed2bd620-dc68-4347-9ac5-3b4335b788dc",
      "metadata": {
        "id": "ed2bd620-dc68-4347-9ac5-3b4335b788dc"
      },
      "source": [
        "### Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0aa3d263-a704-4c67-8718-0ff5c6f5ca81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "0aa3d263-a704-4c67-8718-0ff5c6f5ca81",
        "outputId": "fa5f19ed-920e-4d86-e30e-35cda7ecd463"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3000964939>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "a = torch.zeros(5)\n",
        "b,c = a[:3],a[3:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a8ed5a-72f6-4509-8a9d-9941bfa33271",
      "metadata": {
        "id": "77a8ed5a-72f6-4509-8a9d-9941bfa33271"
      },
      "outputs": [],
      "source": [
        "b[1] = 2\n",
        "c[0] = 6\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389a066a-216f-40eb-90d5-4723ccb42b9f",
      "metadata": {
        "id": "389a066a-216f-40eb-90d5-4723ccb42b9f"
      },
      "outputs": [],
      "source": [
        "def blk_kernel2d_shar(f, blocks, threads, sh_sz, *args, **kwargs):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            shared = torch.zeros(sh_sz) #가상의 shared memory\n",
        "            f(dim3(i1,i0), threads, shared, *args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac969e7d-266d-48f6-9aa7-856ad5de92a0",
      "metadata": {
        "id": "ac969e7d-266d-48f6-9aa7-856ad5de92a0"
      },
      "outputs": [],
      "source": [
        "def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n",
        "    shar_sz = tw*tw\n",
        "    # 실제 CUDA에서는 이렇게 선언됨\n",
        "    # __shared__ float shared[2 * TILE_SIZE * TILE_SIZE];\n",
        "    ms,ns = shared[:shar_sz],shared[shar_sz:] #Shared memory를 2개의 tile로 분할하여 사용, CUDA의 shared memory는 제한적이라 효율성을 위함\n",
        "\n",
        "    for ph in range(cdiv(k,tw)):\n",
        "        idx = ph*tw\n",
        "        # fill shared\n",
        "        for tr in range(blockDim.y):\n",
        "            for tc in range(blockDim.x):\n",
        "                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
        "                ms[tr*tw+tc] = m[ tc+idx + r*k] if r<h and idx+tc<k else 0.\n",
        "                ns[tr*tw+tc] = n[(tr+idx)*w +c] if c<w and idx+tr<k else 0.\n",
        "\n",
        "        # do dotprods from shared\n",
        "        for tr in range(blockDim.y):\n",
        "            for tc in range(blockDim.x):\n",
        "                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
        "                for i in range(tw):\n",
        "                    if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb0c224-5781-4e92-9b59-36a6fa39c909",
      "metadata": {
        "id": "8fb0c224-5781-4e92-9b59-36a6fa39c909"
      },
      "outputs": [],
      "source": [
        "def matmul_2d(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(tw,tw)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
        "                      m.flatten(), n.flatten(), output.flatten(),\n",
        "                      h, w, k, tw=tw)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7021417d-4932-46ac-838e-bbeb0fc27504",
      "metadata": {
        "id": "7021417d-4932-46ac-838e-bbeb0fc27504"
      },
      "outputs": [],
      "source": [
        "m1s.shape, m2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accf5bf5-0874-4a30-aeab-f01034be2a0e",
      "metadata": {
        "id": "accf5bf5-0874-4a30-aeab-f01034be2a0e"
      },
      "outputs": [],
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1a31cf-b54f-4b8a-982f-51ff1a68bb6a",
      "metadata": {
        "id": "4d1a31cf-b54f-4b8a-982f-51ff1a68bb6a"
      },
      "source": [
        "### Python run_threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a44f65b-3ad1-4654-92b9-5b61ede1a6c4",
      "metadata": {
        "id": "6a44f65b-3ad1-4654-92b9-5b61ede1a6c4"
      },
      "outputs": [],
      "source": [
        "def run_threads(f, blockDim, *args, **kwargs):\n",
        "    for i0 in range(blockDim.y):\n",
        "        for i1 in range(blockDim.x): f(i0, i1, *args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096fbfc1-5f01-4203-94df-98a62ddc2ee8",
      "metadata": {
        "id": "096fbfc1-5f01-4203-94df-98a62ddc2ee8"
      },
      "outputs": [],
      "source": [
        "def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n",
        "    shar_sz = tw*tw\n",
        "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
        "\n",
        "    def get_rc(tr, tc): return blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
        "\n",
        "    def fill_shared_tk(tr, tc, ph):\n",
        "        r,c = get_rc(tr, tc)\n",
        "        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n",
        "        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n",
        "\n",
        "    def dotprod_tk(tr, tc):\n",
        "        r,c = get_rc(tr, tc)\n",
        "        for i in range(tw):\n",
        "            if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]\n",
        "\n",
        "    for ph in range(int(math.ceil(k/tw))):\n",
        "        run_threads(fill_shared_tk, blockDim, ph)\n",
        "        run_threads(dotprod_tk, blockDim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ae141e-be1a-42cd-85aa-64be0add9e2f",
      "metadata": {
        "id": "d0ae141e-be1a-42cd-85aa-64be0add9e2f"
      },
      "outputs": [],
      "source": [
        "def matmul_2d(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(tw,tw)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
        "                      m.flatten(), n.flatten(), output.flatten(),\n",
        "                      h, w, k, tw=tw)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb489de0",
      "metadata": {
        "id": "cb489de0"
      },
      "outputs": [],
      "source": [
        "m1s.shape, m2s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e65cb4e9",
      "metadata": {
        "id": "e65cb4e9"
      },
      "outputs": [],
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b204c2-e349-4afb-9787-a9a045b78977",
      "metadata": {
        "id": "31b204c2-e349-4afb-9787-a9a045b78977"
      },
      "source": [
        "### Python threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa6aec96-1e67-4d6d-81af-1f6c3cb6de19",
      "metadata": {
        "id": "fa6aec96-1e67-4d6d-81af-1f6c3cb6de19"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "from threading import Barrier, Thread\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28306d45-3176-4cef-95f1-5894cf494c58",
      "metadata": {
        "id": "28306d45-3176-4cef-95f1-5894cf494c58"
      },
      "outputs": [],
      "source": [
        "def g(x, sb):\n",
        "    print(x)\n",
        "    sb.wait()\n",
        "    print(-x)\n",
        "    sb.wait()\n",
        "    print(x*10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4e712e-5999-4e4b-a057-db65996b657d",
      "metadata": {
        "id": "ff4e712e-5999-4e4b-a057-db65996b657d"
      },
      "outputs": [],
      "source": [
        "num = 3\n",
        "sb = Barrier(num)\n",
        "with ThreadPoolExecutor(num) as ex: list(ex.map(lambda i: g(i,sb), range(1,num+1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac722db-cea2-494f-9ad0-a46c010e61e2",
      "metadata": {
        "id": "bac722db-cea2-494f-9ad0-a46c010e61e2"
      },
      "outputs": [],
      "source": [
        "def blk_kernel2d_shar(f, blocks, tpb, sh_sz, *args, **kwargs):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            shar = torch.zeros(sh_sz)\n",
        "            syncb = Barrier(tpb.y*tpb.x)\n",
        "            threads = [Thread(target=f, args=(dim3(i1,i0), dim3(p,o), tpb, shar, syncb, *args), kwargs=kwargs)\n",
        "                       for o in range(tpb.y) for p in range(tpb.x)]\n",
        "            for tr in threads: tr.start()\n",
        "            for tr in threads: tr.join()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58f86730-7484-404d-b542-861a5516aa72",
      "metadata": {
        "id": "58f86730-7484-404d-b542-861a5516aa72"
      },
      "outputs": [],
      "source": [
        "## CUDA matmul using shared memory\n",
        "def matmul_tiled_bk(blockIdx, threadIdx, blockDim, shared, syncb, m, n, out, h, w, k, tw):\n",
        "    tc,tr = threadIdx.x,threadIdx.y\n",
        "    r = blockIdx.y*blockDim.y + tr\n",
        "    c = blockIdx.x*blockDim.x + tc\n",
        "\n",
        "    shar_sz = tw*tw\n",
        "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
        "\n",
        "    p = 0.\n",
        "    for ph in range(cdiv(k,tw)):\n",
        "        # shared memory tile loading\n",
        "        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n",
        "        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n",
        "        syncb.wait() ## thread syncronize\n",
        "        for i in range(tw): p += ms[tr*tw+i] * ns[tw*i+tc]\n",
        "        syncb.wait() ## thread syncronize\n",
        "\n",
        "    if (r<h and c<w): out[r*w + c] = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f758eb6b-fc56-43e0-943f-3afd8ce86dbc",
      "metadata": {
        "id": "f758eb6b-fc56-43e0-943f-3afd8ce86dbc"
      },
      "outputs": [],
      "source": [
        "def matmul_2d(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(tw,tw)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
        "                      m.flatten(), n.flatten(), output.flatten(),\n",
        "                      h, w, k, tw=tw)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270af122-7282-4934-833d-6fe195efc7b6",
      "metadata": {
        "id": "270af122-7282-4934-833d-6fe195efc7b6"
      },
      "outputs": [],
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s, tw=8), m1s@m2s).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5bfbea5-8cd1-41c0-aca8-298a48599b52",
      "metadata": {
        "id": "d5bfbea5-8cd1-41c0-aca8-298a48599b52"
      },
      "source": [
        "### CUDA dynamic shared"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f42f931-580e-4ced-8735-354abe6499ef",
      "metadata": {
        "id": "0f42f931-580e-4ced-8735-354abe6499ef"
      },
      "source": [
        "Code auto-generated by ChatGPT 4, using the following prompt:\n",
        "\n",
        "> Convert the following python code to CUDA C, keeping formatting and variable names the same where possible. You can remove `blockIdx, threadIdx, blockDim, shared` from the argument list, since they're already provided by CUDA. Change `syncb.wait()` to `__syncthreads`. Use `extern __shared__ float shared[]` to create the `shared` array. Use the C ternary operator to replace the Python equivalent where appropriate. If the Python code uses any non-standard functions, you can assume the same functions are also available to the translated C code with the same name and signature.\n",
        "\n",
        "The generated code worked first time, although we did some minor cleanups afterwards (e.g. renaming `shared` to `ms`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97fa19f4-8ca6-4ce0-a89c-d82a79a71d09",
      "metadata": {
        "id": "97fa19f4-8ca6-4ce0-a89c-d82a79a71d09"
      },
      "outputs": [],
      "source": [
        "#CUDA C++ for matmul of pyton.\n",
        "cuda_src = cuda_begin + r'''\n",
        "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k, int tw) {\n",
        "    int tc=threadIdx.x, tr=threadIdx.y;\n",
        "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
        "\n",
        "    extern __shared__ float ms[]; // dynamic shared memory\n",
        "    float *ns = &ms[tw*tw]; // ns 는 tw*tw 위치부터 배열 할당\n",
        "\n",
        "    float p = 0.0f;\n",
        "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
        "        int idx = ph*tw;\n",
        "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
        "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
        "        __syncthreads();\n",
        "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (r<h && c<w) out[r*w + c] = p;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef35af0-02a5-44f1-ae3e-c05258a62bd7",
      "metadata": {
        "id": "5ef35af0-02a5-44f1-ae3e-c05258a62bd7"
      },
      "outputs": [],
      "source": [
        "# CUDA + Python wapper function.\n",
        "cuda_src += r'''\n",
        "torch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "\n",
        "    /*\n",
        "    // Commented out section demonstrating basic idea of dynamic size calculation\n",
        "    cudaDeviceProp devProp;\n",
        "    CUDA_ERR(cudaGetDeviceProperties(&devProp, 0));\n",
        "    int maxThreads = devProp.maxThreadsPerBlock;\n",
        "    size_t requiredSize = static_cast<size_t>(maxThreads) * 2 * sizeof(float);\n",
        "    size_t size = min(devProp.sharedMemPerBlock, requiredSize);\n",
        "    int TW = std::sqrt(maxThreads);\n",
        "    */\n",
        "\n",
        "    // We just set size fixed for now\n",
        "    int TW = 16;\n",
        "    size_t size = TW*TW * 2 * sizeof(float);\n",
        "    dim3 tpb(TW,TW);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_k<<<blocks,tpb,size>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k, TW);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c81f01-589e-41f9-899a-a2050b1b4fdd",
      "metadata": {
        "id": "e3c81f01-589e-41f9-899a-a2050b1b4fdd"
      },
      "outputs": [],
      "source": [
        "fname = 'matmul_dyn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1a24b0-0cb9-46dd-97fa-4df0bca629d6",
      "metadata": {
        "id": "eb1a24b0-0cb9-46dd-97fa-4df0bca629d6"
      },
      "outputs": [],
      "source": [
        "cpp_src = get_sig(fname, cuda_src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7352ea50-96ca-470e-9a16-360bf09ddd75",
      "metadata": {
        "id": "7352ea50-96ca-470e-9a16-360bf09ddd75"
      },
      "outputs": [],
      "source": [
        "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1895e28c-8fda-403c-bd43-95a481960fbc",
      "metadata": {
        "id": "1895e28c-8fda-403c-bd43-95a481960fbc"
      },
      "outputs": [],
      "source": [
        "torch.isclose(module.matmul_dyn(m1c,m2c), m1c@m2c).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc98195e-0dce-4487-9d85-aec2fdadabae",
      "metadata": {
        "id": "fc98195e-0dce-4487-9d85-aec2fdadabae"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 10\n",
        "module.matmul_dyn(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20fda413-cac6-4f4f-b362-61f6a8db4056",
      "metadata": {
        "id": "20fda413-cac6-4f4f-b362-61f6a8db4056"
      },
      "source": [
        "### CUDA static shared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03d0811-0421-46d2-b67f-dabd7557666d",
      "metadata": {
        "id": "d03d0811-0421-46d2-b67f-dabd7557666d"
      },
      "outputs": [],
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "constexpr int tw = 16;\n",
        "\n",
        "__global__ void matmul_ks(float *m, float *n, float *out, int h, int w, int k) {\n",
        "    __shared__ float ms[tw][tw], ns[tw][tw];\n",
        "    int tc=threadIdx.x, tr=threadIdx.y;\n",
        "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
        "\n",
        "    float p=0.0f;\n",
        "    for (int ph=0; ph < cdiv(k,tw); ++ph) {\n",
        "        int idx = ph*tw;\n",
        "        ms[tr][tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
        "        ns[tr][tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
        "        __syncthreads();\n",
        "        for (int i=0; i<tw; ++i) p += ms[tr][i] * ns[i][tc];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (r<h && c<w) out[r*w + c] = p;\n",
        "}\n",
        "\n",
        "torch::Tensor matmul_static(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "    dim3 tpb(tw,tw);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_ks<<<blocks,tpb>>>(m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bea62d-90ee-41c4-8df2-aca17911ae50",
      "metadata": {
        "id": "36bea62d-90ee-41c4-8df2-aca17911ae50"
      },
      "outputs": [],
      "source": [
        "fname = 'matmul_static'\n",
        "cpp_src = get_sig(fname, cuda_src)\n",
        "module = load_cuda(cuda_src, cpp_src, [fname])\n",
        "torch.isclose(module.matmul_static(m1c,m2c), m1c@m2c).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ab2501-a73a-48d3-9ee5-0c1e508e1fe4",
      "metadata": {
        "id": "f0ab2501-a73a-48d3-9ee5-0c1e508e1fe4"
      },
      "outputs": [],
      "source": [
        "%%timeit -n 10\n",
        "module.matmul_static(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5ab0d1-f574-42e1-9d50-e9ffdcd50861",
      "metadata": {
        "id": "fe5ab0d1-f574-42e1-9d50-e9ffdcd50861"
      },
      "source": [
        "## Numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d0a300-2763-4b9d-a496-eb3c877c006b",
      "metadata": {
        "id": "99d0a300-2763-4b9d-a496-eb3c877c006b"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "from numba.cuda import as_cuda_array as ca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b409312b-1dca-4e63-995d-9b519b61b58f",
      "metadata": {
        "id": "b409312b-1dca-4e63-995d-9b519b61b58f"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def matmul_k_numba(m, n, out, tw):\n",
        "    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n",
        "    tc,tr = tid.x,tid.y\n",
        "    r,c = cbi.y * cbd.y + tr, cbi.x * cbd.x + tc\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "\n",
        "    shar = cuda.shared.array(0, dtype=np.float32)\n",
        "    ms,ns = shar[:tw*tw],shar[tw*tw:2*tw*tw]\n",
        "\n",
        "    p = np.float32(0.0)\n",
        "    for ph in range(math.ceil(k/tw)):\n",
        "        idx = ph*tw\n",
        "        ms[tr*tw+tc] = m[r, tc+idx] if r<h and idx+tc<k else 0.\n",
        "        ns[tr*tw+tc] = n[tr+idx, c] if c<w and idx+tr<k else 0.\n",
        "        cuda.syncthreads()\n",
        "        for i in range(tw): p += ms[tr*tw+i] * ns[i*tw+tc]\n",
        "        cuda.syncthreads()\n",
        "    if r < h and c < w: out[r, c] = p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223cdf11-1d26-44db-8c9b-aaac3607f6b3",
      "metadata": {
        "id": "223cdf11-1d26-44db-8c9b-aaac3607f6b3"
      },
      "outputs": [],
      "source": [
        "def matmul_2d_numba(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    out = torch.zeros(h, w, dtype=m.dtype, device=m.device)\n",
        "    dyn_shared_mem_size = 2 * tw * tw * 4\n",
        "    tpb = tw,tw\n",
        "    blocks = cdiv(w,tpb[0]), cdiv(h,tpb[1])\n",
        "    matmul_k_numba[blocks, tpb, 0, dyn_shared_mem_size](ca(m), ca(n), ca(out), tw)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a09a6c3-e161-4ad1-ad50-c8020847b220",
      "metadata": {
        "id": "4a09a6c3-e161-4ad1-ad50-c8020847b220",
        "outputId": "bee56a1e-54a3-4a36-e28f-998c201c6f5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.isclose(matmul_2d_numba(m1c,m2c), m1c@m2c).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50ac1f7-0a23-4aed-9f45-0cd6db294825",
      "metadata": {
        "id": "d50ac1f7-0a23-4aed-9f45-0cd6db294825",
        "outputId": "234fd5ee-66ce-4322-89c1-ae2bd87bea84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16.2 ms ± 68.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "matmul_2d_numba(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfdd47b1-6abc-47ad-b15c-6655abcbebed",
      "metadata": {
        "id": "bfdd47b1-6abc-47ad-b15c-6655abcbebed"
      },
      "source": [
        "## Extra: Optimised Dynamic CUDA with Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eeb1e8e-69a6-43b2-9ded-c605222a4bf1",
      "metadata": {
        "id": "6eeb1e8e-69a6-43b2-9ded-c605222a4bf1"
      },
      "outputs": [],
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "template<int tw>\n",
        "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n",
        "    int tc=threadIdx.x, tr=threadIdx.y;\n",
        "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
        "    extern __shared__ float ms[];\n",
        "    float *ns = &ms[tw*tw];\n",
        "\n",
        "    float p = 0.0f;\n",
        "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
        "        int idx = ph*tw;\n",
        "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
        "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
        "        __syncthreads();\n",
        "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (r<h && c<w) out[r*w + c] = p;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a5df8d7-d58f-4481-bc6a-f39e7b866c36",
      "metadata": {
        "id": "6a5df8d7-d58f-4481-bc6a-f39e7b866c36"
      },
      "outputs": [],
      "source": [
        "cuda_src += r'''\n",
        "torch::Tensor matmul_dyn1(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "    int TW = 16; // TODO: Calculate this dynamically\n",
        "    size_t size = TW*TW*2 * sizeof(float) + 1;\n",
        "    dim3 tpb(TW,TW);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "\n",
        "    auto f = [&](auto kf) { kf<<<blocks, tpb, size>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    };\n",
        "    switch(TW) {\n",
        "        case 8: f(matmul_k<8>); break;\n",
        "        case 16: f(matmul_k<16>); break;\n",
        "        case 32: f(matmul_k<32>); break;\n",
        "        default: break;\n",
        "    }\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f457f70c-800b-4886-b74d-616704ea31b3",
      "metadata": {
        "id": "f457f70c-800b-4886-b74d-616704ea31b3",
        "outputId": "fe5676cd-a150-4349-8e3a-e1c8cb1fa616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 93.2 ms, sys: 37.3 ms, total: 130 ms\n",
            "Wall time: 43.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "fname = 'matmul_dyn1'\n",
        "cpp_src = get_sig(fname, cuda_src)\n",
        "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)\n",
        "func = getattr(module, fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dd1bfc9-819e-4909-aeef-ff340cd7ac25",
      "metadata": {
        "id": "0dd1bfc9-819e-4909-aeef-ff340cd7ac25",
        "outputId": "a1982ab6-f422-4ab4-ad08-4af700209501"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.isclose(func(m1c,m2c), m1c@m2c).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a1e8e7-238d-46c2-b518-d1e5e8fc6561",
      "metadata": {
        "id": "89a1e8e7-238d-46c2-b518-d1e5e8fc6561",
        "outputId": "e0486c18-0679-4ab9-abb1-cded4925cec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.35 ms ± 13.6 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "func(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fe0c4a-1990-4b07-8c37-c7d44277d1e2",
      "metadata": {
        "id": "35fe0c4a-1990-4b07-8c37-c7d44277d1e2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}